{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abbycakes02/Perceptron/blob/main/neuralnetwork.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bhOSH037M2sS",
        "outputId": "6fb7febe-90d1-4cfa-b26c-e1b99b1d756b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting sklearn\n",
            "  Downloading sklearn-0.0.post7.tar.gz (3.6 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: sklearn\n",
            "  Building wheel for sklearn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sklearn: filename=sklearn-0.0.post7-py3-none-any.whl size=2950 sha256=7bbfe86526383b3e0e11a4c55f3cd7db2fd355aefabe0873345d6658a0616ab2\n",
            "  Stored in directory: /root/.cache/pip/wheels/c8/9c/85/72901eb50bc4bc6e3b2629378d172384ea3dfd19759c77fd2c\n",
            "Successfully built sklearn\n",
            "Installing collected packages: sklearn\n",
            "Successfully installed sklearn-0.0.post7\n"
          ]
        }
      ],
      "source": [
        "!pip3 install sklearn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "957_734uLuQO"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "from sklearn.model_selection import StratifiedKFold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LBldUe9MN0eC"
      },
      "outputs": [],
      "source": [
        "#the key thing is we are passing the # of hidden layer nodes as a parameter. We are going to use this function in order to experiment\n",
        "#with how altering the # of hidden layer nodes impacts our performance.\n",
        "\n",
        "def create_model(hidden_layer_nodes, input_dimensions, output_dimensions):\n",
        "  #make a sequential network that feeds information forward and back propogates\n",
        "  model = tf.keras.Sequential([\n",
        "      tf.keras.layers.Dense(hidden_layer_nodes, activation = 'relu', input_dim = input_dimensions),\n",
        "      tf.keras.layers.Dense(output_dimensions, activation = 'softmax')\n",
        "  ])\n",
        "  model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "  return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NKTYe9xaQ3zb"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(X_train, X_test, y_train, y_test, model, epochs = 100, bs = 8):\n",
        "  #batch size = # of examples that we are going to feed forward and then backpropogate the error and update their weights accoringly at\n",
        "  # a time\n",
        "  model.fit(X_train,y_train,epochs = epochs, batch_size = bs, verbose = 0)\n",
        "  y_pred = model.predict(X_test)\n",
        "  y_pred_classes = np.argmax(y_pred, axis = 1)\n",
        "  y_test_classes = np.argmax(y_test, axis = 1)\n",
        "  loss, acurracy = model.evaluate(X_test, y_test, verbose = 0)\n",
        "  precision = precision_score(y_test_classes, y_pred_classes, average = \"macro\")\n",
        "  recall = recall_score(y_test_classes, y_pred_classes, average = \"macro\")\n",
        "  f1 = f1_score(y_test_classes, y_pred_classes, average = \"macro\")\n",
        "  cm = confusion_matrix(y_test_classes, y_pred_classes)\n",
        "  return loss, acurracy, precision, recall, f1, cm\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2gSktFtuGpId",
        "outputId": "53796ca7-af3f-4f4d-89ad-085782267984"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "number of hidden layers nodes 4\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 62ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "mean_loss is 0.23100544810295104\n",
            "mean_accuracy is 0.9533333301544189\n",
            "mean_precision is 0.9539393939393939\n",
            "mean_recall is 0.9533333333333334\n",
            "mean_f1 is 0.9533166248955723\n",
            "number of hidden layers nodes 8\n",
            "1/1 [==============================] - 0s 68ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "mean_loss is 0.13722097128629684\n",
            "mean_accuracy is 0.9599999785423279\n",
            "mean_precision is 0.9646464646464648\n",
            "mean_recall is 0.96\n",
            "mean_f1 is 0.9597984861142755\n",
            "number of hidden layers nodes 12\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "mean_loss is 0.11052779853343964\n",
            "mean_accuracy is 0.9466666460037232\n",
            "mean_precision is 0.9531002331002331\n",
            "mean_recall is 0.9466666666666667\n",
            "mean_f1 is 0.9470047098422384\n",
            "number of hidden layers nodes 20\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 66ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "mean_loss is 0.08963831663131713\n",
            "mean_accuracy is 0.9599999785423279\n",
            "mean_precision is 0.9646464646464648\n",
            "mean_recall is 0.96\n",
            "mean_f1 is 0.9597984861142755\n"
          ]
        }
      ],
      "source": [
        "irisds = load_iris()\n",
        "X, y = irisds.data, irisds.target\n",
        "\n",
        "k = 5\n",
        "hidden_layer_nodes = [4, 8, 12, 20]\n",
        "epochs = 200\n",
        "batch_size = 16\n",
        "\n",
        "for hidden_nodes in hidden_layer_nodes:\n",
        "  print(f\"number of hidden layers nodes {hidden_nodes}\")\n",
        "  all_metrics = cross_val_with_hyperparams(X, y, k, hidden_nodes, epochs, batch_size)\n",
        "  mean_loss = np.mean([ m['loss'] for m in all_metrics])\n",
        "  mean_accuracy = np.mean([ m['accuracy'] for m in all_metrics])\n",
        "  mean_precision = np.mean([ m['precision'] for m in all_metrics])\n",
        "  mean_recall = np.mean([ m['recall'] for m in all_metrics])\n",
        "  mean_f1 = np.mean([ m['f1'] for m in all_metrics])\n",
        "  print(f\"mean_loss is {mean_loss}\")\n",
        "  print(f\"mean_accuracy is {mean_accuracy}\")\n",
        "  print(f\"mean_precision is {mean_precision}\")\n",
        "  print(f\"mean_recall is {mean_recall}\")\n",
        "  print(f\"mean_f1 is {mean_f1}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gIU3Z8SeCGqc"
      },
      "outputs": [],
      "source": [
        "def cross_val_with_hyperparams(X, y, k, hidden_layer_nodes, epochs = 100, batch_size = 8):\n",
        "  encoder = OneHotEncoder(sparse_output= False)\n",
        "  y_onehot = encoder.fit_transform(y.reshape(-1, 1))\n",
        "  scaler = StandardScaler()\n",
        "  X = scaler.fit_transform(X)\n",
        "  input_dimensions = X.shape[1]\n",
        "  output_dimensions = len(np.unique(y))\n",
        "  kfold = StratifiedKFold(n_splits = k, shuffle = True, random_state = 17)\n",
        "  all_metrics = []\n",
        "  for train_index, test_index in kfold.split(X, y):\n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    y_train, y_test = y_onehot[train_index], y_onehot[test_index]\n",
        "    model = create_model(hidden_layer_nodes, input_dimensions, output_dimensions)\n",
        "    loss, acurracy, precision, recall, f1, cm = evaluate_model(X_train, X_test, y_train, y_test, model, epochs = epochs, bs = batch_size)\n",
        "    all_metrics.append({\"loss\": loss, \"accuracy\": acurracy, \"precision\": precision, \"recall\": recall, \"f1\": f1, \"cm\": cm })\n",
        "  return all_metrics\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xov4ac6sV5GI"
      },
      "outputs": [],
      "source": [
        "def create_model(hidden_layer_nodes, input_dimensions, output_dimensions, num_hidden_layers):\n",
        "  model = tf.keras.Sequential()\n",
        "  model.add(tf.keras.layers.Dense(hidden_layer_nodes, activation = \"relu\", input_dim = input_dimensions))\n",
        "  for _ in range(num_hidden_layers-1):\n",
        "    model.add(tf.keras.layers.Dense(hidden_layer_nodes, activation = \"relu\"))\n",
        "  model.add(tf.keras.layers.Dense(output_dimensions, activation = \"softmax\"))\n",
        "  model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "  return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LAkbonutYmfD"
      },
      "outputs": [],
      "source": [
        "def cross_val_with_hyperparams(X, y, k, hidden_layer_nodes, hidden_layers, epochs = 100, batch_size = 8):\n",
        "  encoder = OneHotEncoder(sparse_output= False)\n",
        "  y_onehot = encoder.fit_transform(y.reshape(-1, 1))\n",
        "  scaler = StandardScaler()\n",
        "  X = scaler.fit_transform(X)\n",
        "  input_dimensions = X.shape[1]\n",
        "  output_dimensions = len(np.unique(y))\n",
        "  kfold = StratifiedKFold(n_splits = k, shuffle = True, random_state = 17)\n",
        "  all_metrics = []\n",
        "  for train_index, test_index in kfold.split(X, y):\n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    y_train, y_test = y_onehot[train_index], y_onehot[test_index]\n",
        "    model = create_model(hidden_layer_nodes, input_dimensions, output_dimensions, hidden_layers)\n",
        "    loss, acurracy, precision, recall, f1, cm = evaluate_model(X_train, X_test, y_train, y_test, model, epochs = epochs, bs = batch_size)\n",
        "    all_metrics.append({\"loss\": loss, \"accuracy\": acurracy, \"precision\": precision, \"recall\": recall, \"f1\": f1, \"cm\": cm })\n",
        "  return all_metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X4azWmqLZcu0",
        "outputId": "2d56987b-d5af-435e-e233-f40e4b4d333f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "number of hidden layers 1\n",
            "number of hidden layers nodes 4\n",
            "1/1 [==============================] - 0s 156ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 77ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7eec6f6d3760> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 53ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_test_function.<locals>.test_function at 0x7eec4c13b370> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mean_loss is 0.192956805229187\n",
            "mean_accuracy is 0.9333333134651184\n",
            "mean_precision is 0.9396322196322195\n",
            "mean_recall is 0.9333333333333332\n",
            "mean_f1 is 0.932789433088262\n",
            "number of hidden layers nodes 8\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7eec4c1393f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 48ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_test_function.<locals>.test_function at 0x7eec4c374ee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "mean_loss is 0.12285612970590591\n",
            "mean_accuracy is 0.9466666460037232\n",
            "mean_precision is 0.948956228956229\n",
            "mean_recall is 0.9466666666666667\n",
            "mean_f1 is 0.9465664160401002\n",
            "number of hidden layers nodes 12\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "mean_loss is 0.09369186013936996\n",
            "mean_accuracy is 0.9666666507720947\n",
            "mean_precision is 0.9684848484848484\n",
            "mean_recall is 0.9666666666666668\n",
            "mean_f1 is 0.9666165413533834\n",
            "number of hidden layers nodes 20\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 73ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "mean_loss is 0.0931976318359375\n",
            "mean_accuracy is 0.9599999785423279\n",
            "mean_precision is 0.9664335664335664\n",
            "mean_recall is 0.96\n",
            "mean_f1 is 0.9603380431755717\n",
            "number of hidden layers 2\n",
            "number of hidden layers nodes 4\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 61ms/step\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "mean_loss is 0.15519867539405824\n",
            "mean_accuracy is 0.9399999856948853\n",
            "mean_precision is 0.9502719502719504\n",
            "mean_recall is 0.9400000000000001\n",
            "mean_f1 is 0.9392368647988516\n",
            "number of hidden layers nodes 8\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "mean_loss is 0.07831907495856286\n",
            "mean_accuracy is 0.9666666388511658\n",
            "mean_precision is 0.9696969696969697\n",
            "mean_recall is 0.9666666666666666\n",
            "mean_f1 is 0.9665831244778612\n",
            "number of hidden layers nodes 12\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "mean_loss is 0.07695935517549515\n",
            "mean_accuracy is 0.9599999904632568\n",
            "mean_precision is 0.9634343434343435\n",
            "mean_recall is 0.96\n",
            "mean_f1 is 0.9598319029897976\n",
            "number of hidden layers nodes 20\n",
            "1/1 [==============================] - 0s 60ms/step\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 66ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "mean_loss is 0.11298384107649326\n",
            "mean_accuracy is 0.9599999904632568\n",
            "mean_precision is 0.9652214452214452\n",
            "mean_recall is 0.96\n",
            "mean_f1 is 0.9603714600510939\n",
            "number of hidden layers 3\n",
            "number of hidden layers nodes 4\n",
            "1/1 [==============================] - 0s 60ms/step\n",
            "1/1 [==============================] - 0s 100ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 60ms/step\n",
            "1/1 [==============================] - 0s 61ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mean_loss is 0.35402409434318544\n",
            "mean_accuracy is 0.8333333194255829\n",
            "mean_precision is 0.7907070707070707\n",
            "mean_recall is 0.8333333333333333\n",
            "mean_f1 is 0.7999498746867167\n",
            "number of hidden layers nodes 8\n",
            "1/1 [==============================] - 0s 60ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 88ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "mean_loss is 0.07784879729151725\n",
            "mean_accuracy is 0.9733333230018616\n",
            "mean_precision is 0.9745454545454546\n",
            "mean_recall is 0.9733333333333334\n",
            "mean_f1 is 0.9732999164578111\n",
            "number of hidden layers nodes 12\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 70ms/step\n",
            "1/1 [==============================] - 0s 61ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "mean_loss is 0.14514271430671216\n",
            "mean_accuracy is 0.9666666507720947\n",
            "mean_precision is 0.9724941724941726\n",
            "mean_recall is 0.9666666666666668\n",
            "mean_f1 is 0.9670214182799995\n",
            "number of hidden layers nodes 20\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "mean_loss is 0.21472331508994102\n",
            "mean_accuracy is 0.9466666579246521\n",
            "mean_precision is 0.9523232323232322\n",
            "mean_recall is 0.9466666666666667\n",
            "mean_f1 is 0.9463638895217843\n"
          ]
        }
      ],
      "source": [
        "irisds = load_iris()\n",
        "X, y = irisds.data, irisds.target\n",
        "\n",
        "k = 5\n",
        "hidden_layer_nodes = [4, 8, 12, 20]\n",
        "hidden_layers = [1, 2, 3]\n",
        "epochs = 200\n",
        "batch_size = 16\n",
        "for hidden_layer in hidden_layers:\n",
        "  print(f\"number of hidden layers {hidden_layer}\")\n",
        "  for hidden_nodes in hidden_layer_nodes:\n",
        "    print(f\"number of hidden layers nodes {hidden_nodes}\")\n",
        "    all_metrics = cross_val_with_hyperparams(X, y, k, hidden_nodes, hidden_layer, epochs, batch_size)\n",
        "    mean_loss = np.mean([ m['loss'] for m in all_metrics])\n",
        "    mean_accuracy = np.mean([ m['accuracy'] for m in all_metrics])\n",
        "    mean_precision = np.mean([ m['precision'] for m in all_metrics])\n",
        "    mean_recall = np.mean([ m['recall'] for m in all_metrics])\n",
        "    mean_f1 = np.mean([ m['f1'] for m in all_metrics])\n",
        "    print(f\"mean_loss is {mean_loss}\")\n",
        "    print(f\"mean_accuracy is {mean_accuracy}\")\n",
        "    print(f\"mean_precision is {mean_precision}\")\n",
        "    print(f\"mean_recall is {mean_recall}\")\n",
        "    print(f\"mean_f1 is {mean_f1}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5h6Qt0x2c8aI",
        "outputId": "c61100ed-2f25-417c-b17a-dd4160433fbb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 61ms/step\n",
            "1/1 [==============================] - 0s 72ms/step\n",
            "1/1 [==============================] - 0s 60ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "mean_loss is 0.192274259775877\n",
            "mean_accuracy is 0.9466666460037232\n",
            "mean_precision is 0.9496969696969696\n",
            "mean_recall is 0.9466666666666667\n",
            "mean_f1 is 0.9469172932330828\n"
          ]
        }
      ],
      "source": [
        "    all_metrics = cross_val_with_hyperparams(X, y, k, 20, 3, 350, batch_size)\n",
        "    mean_loss = np.mean([ m['loss'] for m in all_metrics])\n",
        "    mean_accuracy = np.mean([ m['accuracy'] for m in all_metrics])\n",
        "    mean_precision = np.mean([ m['precision'] for m in all_metrics])\n",
        "    mean_recall = np.mean([ m['recall'] for m in all_metrics])\n",
        "    mean_f1 = np.mean([ m['f1'] for m in all_metrics])\n",
        "    print(f\"mean_loss is {mean_loss}\")\n",
        "    print(f\"mean_accuracy is {mean_accuracy}\")\n",
        "    print(f\"mean_precision is {mean_precision}\")\n",
        "    print(f\"mean_recall is {mean_recall}\")\n",
        "    print(f\"mean_f1 is {mean_f1}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5aTGLUTlmYAX"
      },
      "outputs": [],
      "source": [
        "def create_model(hidden_layer_nodes, input_dimensions, output_dimensions, num_hidden_layers, drop_out = 0.5):\n",
        "  model = tf.keras.Sequential()\n",
        "  model.add(tf.keras.layers.Dense(hidden_layer_nodes, activation = \"relu\", input_dim = input_dimensions))\n",
        "  model.add(tf.keras.layers.Dropout(drop_out))\n",
        "  for _ in range(num_hidden_layers-1):\n",
        "    model.add(tf.keras.layers.Dense(hidden_layer_nodes, activation = \"relu\"))\n",
        "    model.add(tf.keras.layers.Dropout(drop_out))\n",
        "  model.add(tf.keras.layers.Dense(output_dimensions, activation = \"softmax\"))\n",
        "  model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "eIM8-TS8m9Aj",
        "outputId": "2ac13de1-bfdc-4913-b3cc-9feae77033eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "number of hidden layers 1\n",
            "number of hidden layers nodes 4\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 81ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "mean_loss is 0.4142501771450043\n",
            "mean_accuracy is 0.8799999833106995\n",
            "mean_precision is 0.8968039368039367\n",
            "mean_recall is 0.8800000000000001\n",
            "mean_f1 is 0.8772505859704676\n",
            "number of hidden layers nodes 8\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "mean_loss is 0.24183949530124665\n",
            "mean_accuracy is 0.9466666460037232\n",
            "mean_precision is 0.9531002331002331\n",
            "mean_recall is 0.9466666666666667\n",
            "mean_f1 is 0.9461561832971175\n",
            "number of hidden layers nodes 12\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "1/1 [==============================] - 0s 92ms/step\n",
            "1/1 [==============================] - 0s 84ms/step\n",
            "1/1 [==============================] - 0s 83ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "mean_loss is 0.2066779464483261\n",
            "mean_accuracy is 0.9333333134651184\n",
            "mean_precision is 0.9462626262626262\n",
            "mean_recall is 0.9333333333333333\n",
            "mean_f1 is 0.9310609857978278\n",
            "number of hidden layers nodes 20\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "mean_loss is 0.12669719457626344\n",
            "mean_accuracy is 0.9666666507720947\n",
            "mean_precision is 0.9684848484848484\n",
            "mean_recall is 0.9666666666666668\n",
            "mean_f1 is 0.9666165413533834\n",
            "number of hidden layers 2\n",
            "number of hidden layers nodes 4\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 89ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 87ms/step\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "mean_loss is 0.5634447455406189\n",
            "mean_accuracy is 0.8866666555404663\n",
            "mean_precision is 0.8572390572390572\n",
            "mean_recall is 0.8866666666666665\n",
            "mean_f1 is 0.8642262221209588\n",
            "number of hidden layers nodes 8\n",
            "1/1 [==============================] - 0s 68ms/step\n",
            "1/1 [==============================] - 0s 63ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 87ms/step\n",
            "1/1 [==============================] - 0s 79ms/step\n",
            "mean_loss is 0.3224530667066574\n",
            "mean_accuracy is 0.9266666531562805\n",
            "mean_precision is 0.9359692159692159\n",
            "mean_recall is 0.9266666666666665\n",
            "mean_f1 is 0.9254720133667501\n",
            "number of hidden layers nodes 12\n",
            "1/1 [==============================] - 0s 82ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 61ms/step\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "mean_loss is 0.1939221054315567\n",
            "mean_accuracy is 0.95333331823349\n",
            "mean_precision is 0.9595959595959597\n",
            "mean_recall is 0.9533333333333334\n",
            "mean_f1 is 0.9530138477506899\n",
            "number of hidden layers nodes 20\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 65ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "mean_loss is 0.11651714444160462\n",
            "mean_accuracy is 0.95333331823349\n",
            "mean_precision is 0.9573737373737373\n",
            "mean_recall is 0.9533333333333334\n",
            "mean_f1 is 0.95314852788537\n",
            "number of hidden layers 3\n",
            "number of hidden layers nodes 4\n",
            "1/1 [==============================] - 0s 68ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 65ms/step\n",
            "1/1 [==============================] - 0s 103ms/step\n",
            "1/1 [==============================] - 0s 62ms/step\n",
            "1/1 [==============================] - 0s 61ms/step\n",
            "mean_loss is 0.6801216959953308\n",
            "mean_accuracy is 0.8066666722297668\n",
            "mean_precision is 0.7998364598364598\n",
            "mean_recall is 0.8066666666666666\n",
            "mean_f1 is 0.772292108762697\n",
            "number of hidden layers nodes 8\n",
            "1/1 [==============================] - 0s 62ms/step\n",
            "1/1 [==============================] - 0s 62ms/step\n",
            "1/1 [==============================] - 0s 66ms/step\n",
            "1/1 [==============================] - 0s 103ms/step\n",
            "1/1 [==============================] - 0s 71ms/step\n",
            "mean_loss is 0.3425520181655884\n",
            "mean_accuracy is 0.9133333206176758\n",
            "mean_precision is 0.9233359233359234\n",
            "mean_recall is 0.9133333333333333\n",
            "mean_f1 is 0.9125033643811407\n",
            "number of hidden layers nodes 12\n",
            "1/1 [==============================] - 0s 66ms/step\n",
            "1/1 [==============================] - 0s 62ms/step\n",
            "1/1 [==============================] - 0s 62ms/step\n",
            "1/1 [==============================] - 0s 68ms/step\n",
            "1/1 [==============================] - 0s 62ms/step\n",
            "mean_loss is 0.2773332953453064\n",
            "mean_accuracy is 0.9266666650772095\n",
            "mean_precision is 0.9356060606060608\n",
            "mean_recall is 0.9266666666666665\n",
            "mean_f1 is 0.9259765575555049\n",
            "number of hidden layers nodes 20\n",
            "1/1 [==============================] - 0s 65ms/step\n",
            "1/1 [==============================] - 0s 61ms/step\n",
            "1/1 [==============================] - 0s 61ms/step\n",
            "1/1 [==============================] - 0s 63ms/step\n",
            "1/1 [==============================] - 0s 67ms/step\n",
            "mean_loss is 0.13466150015592576\n",
            "mean_accuracy is 0.9599999785423279\n",
            "mean_precision is 0.9624242424242425\n",
            "mean_recall is 0.96\n",
            "mean_f1 is 0.9599331662489557\n"
          ]
        }
      ],
      "source": [
        "irisds = load_iris()\n",
        "X, y = irisds.data, irisds.target\n",
        "\n",
        "k = 5\n",
        "hidden_layer_nodes = [4, 8, 12, 20]\n",
        "hidden_layers = [1, 2, 3]\n",
        "epochs = 200\n",
        "batch_size = 16\n",
        "for hidden_layer in hidden_layers:\n",
        "  print(f\"number of hidden layers {hidden_layer}\")\n",
        "  for hidden_nodes in hidden_layer_nodes:\n",
        "    print(f\"number of hidden layers nodes {hidden_nodes}\")\n",
        "    all_metrics = cross_val_with_hyperparams(X, y, k, hidden_nodes, hidden_layer, epochs = epochs, batch_size = batch_size)\n",
        "    mean_loss = np.mean([ m['loss'] for m in all_metrics])\n",
        "    mean_accuracy = np.mean([ m['accuracy'] for m in all_metrics])\n",
        "    mean_precision = np.mean([ m['precision'] for m in all_metrics])\n",
        "    mean_recall = np.mean([ m['recall'] for m in all_metrics])\n",
        "    mean_f1 = np.mean([ m['f1'] for m in all_metrics])\n",
        "    print(f\"mean_loss is {mean_loss}\")\n",
        "    print(f\"mean_accuracy is {mean_accuracy}\")\n",
        "    print(f\"mean_precision is {mean_precision}\")\n",
        "    print(f\"mean_recall is {mean_recall}\")\n",
        "    print(f\"mean_f1 is {mean_f1}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMpVkHrSeWLkOmyUP+xsw62",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}